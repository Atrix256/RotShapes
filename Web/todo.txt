* gather todo's from cpp and put them here if you dont want to do them right away.

* Encoding:
 1) make an array that is [angle][256] that has a float value in it.
 2) do a double for loop of angle & 256.
 3) Find each pixel that resides in that angle and distance, and add 1 for white, subtract 1 for black
   3a) Possibly multiply the value by what percentage the pixel is in the arc
 4) greater than 0 equals white, less than zero equals black.

* make javascript encoding be on parity with cpp encoding.

* rename the javascript variables to make more intuitive sense.  like colorChannels instead of pixelArray.

* organize code better and clean it up. maybe into separate, reusable javascript functions for other pages

* a page to combine multiple rotshape images into a "spritesheet" or animation file.
 * this could maybe be the playground too?
 * or just keep it minimal

* make a 0-255 texture, look at it both as squared and unsquared distances

* the thing where if you have 2 annulii next to 1 anulus, and the 1 anulus is closer to the outer anulus, push it out to the second one, to help bilinear filtering

* even with a programatically perfect target, we have a problem at angle 0 with bilinear filtering.   should be easy enough to track and fix!

* even with a programattically perfect spiral, we have a problem with noise. AA? not sure what the deal is... maybe need to try C++ barebones encoder and see if it has same result.

* with the batman logo, if you make everything half as large, you can see that the hypotneuse distance isn't quite right

=====

* let the user specify a color for each channel range (0-R, R-G, G-B, B-A).  by default it'd be black/white/black/white but doesn't have to be (plus could use this to help debug whats going on)

* a command line encoder / decoder to remove AA from the equation and to have another way to do it.

Later...
* a playground to investigate the properties of the image (scale, zoom, tint, anti aliasing, etc)
 * in webgl?
 * w/ animation
 * stroke and drop shadow

* make a different page tool to combine multiple single frame images into a multi frame image
 * multiple encoded frames in one image (for sprite sheets and animation)
 * be able to animate the preview (result) for multi frame images
  * maybe only bilinear filter on x axis

* a performance test playground vs a regular texture

* share pixel shader code to decode rot images from UV coordinates

* show shader code to decode rot images, based on options selected!

* a playground that lets you layer multiple tinted (and animated?) layers?

* see how this holds up to dxt compression (maybe jpg too?)

* sample library & research
 * text
 * asian text
 * google icons
 * animated icons
 * get pixel artists involved

* benchmark vs other methods (regular textures & distance textures)

* animate / distort shape by putting distance (source? encoded?) through functions over time. also texture offset animated over time for rotation effects!

* rename distsq to something more generic since it might be squared or not

* Display C code for encoded image data (and writing it to a file??)

* add a checkbox to show the origin on the result image?

=====RESEARCH=====

* asian characters

* more clipart

* english characters and numbers in a couple diff fonts

* try making some textures programatically, to see if you have better results than when encoding existing images.

* test web stuff in IE, Firefox, and on mac

* seems like theres black dots and gaps getting into the data somehow. need to figure that out.
 * investigate in C++, but it's likely due to neighboring black pixels.  need to elimnate not just thinnest sections first, but also least wide as far as by fewerst angles on the arc.

* bug: the anti aliasing (smoothstep) is what causes the hole in the middle when the middle is filled in, fix! (maybe symptom of bug below)

* bug: fill in the middle, set to 512x512 results and 1024 encoded. problems!

* there are definitely some non black & white pixels in the source data when reading it.  that might be causing problems with the encoding.
 * could try saving image and forcing it to white/black and re-loading it, and seeing difference

* default value for channels should be 255, r/2, g/2, b/2/  try it anyways (kinda having some issues with it when first trying it)

* source/result image 256,256. changing encoded size matters, but keeps the same shape.  result to 512,512 and suddenly all sorts of artifacts start coming out! (bilinear sampling off)
 * maybe just a bug? or some inherant issue that needs looking at!
 * probably due to encoding.  we don't fill in multiple buckets when encoding, so there is probably uninitialized information in those buckets.

* when result image is extra small there might be problems from not enough info taken from encoded data.  Need to use mips i think, possibly w/ custom mip making code?

* use shape as alpha texture for texture for decaling

* do texture offset to rotate image

* try w/ color (animated?) source images converted into multiple layers

=====NOTES=====

* why does bilinear texture sampling have such problems with artifacts?
 * has to do with the fact that things next to eachother in space may be encoded in different color channels, so the interpolation sucks
 * also, making the "empty pixel" values better helped this

=====NAME=====

* polar something or rather?

* dual annulus polar shape encoding!

=====REFERENCES=====
 * valve distance textures

 * valve distance texture references!

Signed distance fields with sharp boundaries (harvest for more references too!)
http://lambdacube3d.wordpress.com/2014/11/12/playing-around-with-font-rendering/

diffusion curves?
http://maverick.inria.fr/Publications/2008/OBWBTS08/

generalized vornoi diagrams?
https://www.sthu.org/research/voronoidiagrams/

=====FUTURE WORK=====

* some kind of blur pass to smooth data (but might lose details from source image!)

* find out how to make bilinear filtering work better.  "empty" angles next to non empty.  it will blend and make things go to 0 or 255 ):

* other ways of converting images to the encoded image
   * like, instead of casting a ray, could do a cone and average distances found or something.
   * could use bressenham's algorithm if just casting a ray.
   * probably lots of diff ways

* look at being able to do AA in "squared distance space" somehow?
 * only matters if encoding in squared distance, and squared distance has bad results

* could decrease # of color channels if you don't need all this info.
 * 2 color channels = out, in, out (1 spiral)
 * 1 color channel = in (could describe a convex shape)

* heuristic for which features to keep (middle, thickest, inside, outside, etc)

* maybe horizontal AA can be achieved (or helped) when creating the radial image, to reduce horizontal aliasing?

* instead of RGBA having 4 distances with 256 distances for each channel, could have RG,BA represent 2 distances with 65536 distances each.
 * or 1 uint32 distance for convex shapes

* bilinear filtering has problems because even when white pixels are next to eachother, they may be encoded in different channels!!
 * various situations, seem fixable with specific changes, maybe more to think about here.
 * can we stabalize it somehow?
 * maybe low pass filter changes somehow so big changes in the filter lookup are ignored?

* use splines to interpolate between encoded pixels, instead of relying on bilinear filtering
 * possibly encode spline information in the encoded data instead of just distances.
 * could have some iterative "lease squared error" metric in encoding

=====NOTES=====

* the paper should be in two parts... 1) using the shapes encoded in this way.  2) converting images to this encoding.

* squared distance makes for worse images in the end in my testing (verify w/ smoother art?)
 * could show this in action somehow.

? what should happen if result isn't square but source is.  Should it stretch?
 ! this is controlled by however the UV coordinates are set up.

? fill tool in encoder?
 ! there is no flood fill in javascript/html5 so would need to code it by hand.  image important should be good enough.

? we dont use the full range of the float (0-1) for each color channel, maybe we can improve that
 * not all colors are meaningful, that means we aren't using the full data space available
 * more complex shape decoding likely waranted for more accuracy.  video cards have more processing power, and are more often limited by memory access.
